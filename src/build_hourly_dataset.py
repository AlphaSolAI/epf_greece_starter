import pandas as pd
import numpy as np
from pathlib import Path
import sys
import io
import warnings

# UTF-8 output Î³Î¹Î± Î½Î± Î¼Î·Î½ Î²Î»Î­Ï€ÎµÎ¹Ï‚ Î¹ÎµÏÎ¿Î³Î»Ï…Ï†Î¹ÎºÎ¬
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
warnings.filterwarnings("ignore")

ROOT = Path(__file__).resolve().parents[1]
RAW_DIR = ROOT / "data" / "raw"
HENEX_DIRS = sorted(RAW_DIR.glob("*_EL-DAM_Results"))  # 2020_EL-DAM_Results ÎºÎ»Ï€
LOAD_DIR = RAW_DIR / "load"

OUT_PATH = ROOT / "data" / "processed" / "hourly.parquet"


# ----------------- helpers ----------------- #
def _find_col(columns_map, keyword):
    """Î’ÏÎµÏ‚ Ï„Î·Î½ Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î· Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï„Î¿ keyword (case-insensitive)."""
    keyword = keyword.upper()
    for col, name in columns_map.items():
        if keyword in name:
            return col
    return None


def parse_henex_file(path: Path):
    """
    Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ Î­Î½Î± HenEx EL-DAM_Results xlsx ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹:
        timestamp, price
    ÏŒÏ€Î¿Ï… timestamp ÎµÎ¯Î½Î±Î¹ Î· DELIVERY_MTU ÎºÎ±Î¹ price Ï„Î¿ MCP.
    Î“Î¯Î½ÎµÏ„Î±Î¹ ÏŒÏƒÎ¿ Ï€Î¹Î¿ robust Î³Î¯Î½ÎµÏ„Î±Î¹.
    """
    try:
        df = pd.read_excel(path, engine="openpyxl")
        if df.empty:
            return None

        # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½ ÏƒÏ„Î·Î»ÏÎ½
        col_map = {c: str(c).strip().upper() for c in df.columns}

        mcp_col = _find_col(col_map, "MCP")
        mtu_col = _find_col(col_map, "DELIVERY_MTU")
        zone_col = _find_col(col_map, "BIDDING_ZONE")
        dday_col = _find_col(col_map, "DDAY")

        if mcp_col is None or mtu_col is None:
            # Î§Ï‰ÏÎ¯Ï‚ MCP / DELIVERY_MTU Î´ÎµÎ½ ÎºÎ¬Î½Î¿Ï…Î¼Îµ Ï„Î¯Ï€Î¿Ï„Î±
            return None

        # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î³Î¹Î± Mainland Greece Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¶ÏÎ½Î·
        if zone_col is not None:
            mask_zone = df[zone_col].astype(str).str.contains(
                "Mainland", case=False, na=False
            )
            df = df[mask_zone]

        # Î¤Î¹Î¼Î­Ï‚
        prices = df[mcp_col]

        # MCP Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¼Îµ ÎºÏŒÎ¼Î¼Î± Ï‰Ï‚ Î´ÎµÎºÎ±Î´Î¹ÎºÏŒ
        if prices.dtype == object:
            prices = (
                prices.astype(str)
                .str.replace(",", ".", regex=False)
                .str.replace(" ", "", regex=False)
            )

        prices = pd.to_numeric(prices, errors="coerce")

        # Î§ÏÏŒÎ½Î¿Ï‚
        ts = pd.to_datetime(df[mtu_col], errors="coerce")

        # Î‘Î½ (Î³Î¹Î± ÎºÎ¬Ï€Î¿Î¹Î¿ Î»ÏŒÎ³Î¿) Ï„Î¿ DELIVERY_MTU ÎµÎ¯Î½Î±Î¹ Î¼ÏŒÎ½Î¿ ÏÏÎ±,
        # Ï„ÏŒÏ„Îµ ÏƒÏ…Î½Î¸Î­Ï„Î¿Ï…Î¼Îµ Î±Ï€ÏŒ DDAY + ÏÏÎ±
        if ts.isna().all() and dday_col is not None:
            days = pd.to_datetime(df[dday_col].astype(str), format="%Y%m%d", errors="coerce")
            times = pd.to_datetime(df[mtu_col].astype(str), errors="coerce").dt.time
            ts = pd.to_datetime(
                days.dt.strftime("%Y-%m-%d") + " " + pd.Series(times).astype(str),
                errors="coerce",
            )

        out = pd.DataFrame({"timestamp": ts, "price": prices})
        out = out.dropna(subset=["timestamp", "price"])

        if out.empty:
            return None

        # ÎšÎ¬Ï€Î¿Î¹ÎµÏ‚ ÏÏÎµÏ‚ ÎµÎ¯Î½Î±Î¹ 15Î»ÎµÏ€Ï„ÎµÏ‚ (00:00, 00:15 ÎºÎ»Ï€).
        # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Î¼Î­ÏƒÎ¿ ÏŒÏÎ¿ Î±Î½Î¬ ÏÏÎ±.
        out["timestamp_hour"] = out["timestamp"].dt.floor("H")
        out = (
            out.groupby("timestamp_hour")["price"]
            .mean()
            .reset_index()
            .rename(columns={"timestamp_hour": "timestamp"})
        )

        return out

    except Exception:
        return None


def parse_admie_load_hourly(path: Path):
    """
    Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î¿ RealTimeSCADASystemLoad_01.xls (.xls) ÎºÎ±Î¹ Ï†Ï„Î¹Î¬Ï‡Î½ÎµÎ¹:
        timestamp, load
    Î±Ï€ÏŒ ÏƒÏ„Î®Î»ÎµÏ‚:
        Date | 01 | 02 | ... | 24
    Î¤Î¿ mapping ÎµÎ¯Î½Î±Î¹: ÏÏÎ± 1 -> 00:00, 2 -> 01:00, ..., 24 -> 23:00.
    """
    try:
        # Scan Î³Î¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï„Î· Î³ÏÎ±Î¼Î¼Î® Î¼Îµ Ï„Î¿ header
        df_scan = pd.read_excel(path, header=None, nrows=25, engine="xlrd")
        header_idx = -1
        for i, row in df_scan.iterrows():
            row_vals = [str(v).strip().lower() for v in row.values]
            if any("date" in x or "Î·Î¼ÎµÏ" in x for x in row_vals) and any(
                x == "1" or x == "1.0" for x in row_vals
            ):
                header_idx = i
                break

        if header_idx == -1:
            return None

        df = pd.read_excel(path, header=header_idx, engine="xlrd")
        df.columns = [str(c).strip() for c in df.columns]

        # ÏƒÏ„Î®Î»Î· Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚
        date_col = None
        for c in df.columns:
            if "date" in c.lower() or "Î·Î¼ÎµÏ" in c.lower():
                date_col = c
                break
        if date_col is None:
            return None

        # ÏƒÏ„Î®Î»ÎµÏ‚ Î¼Îµ ÏÏÎµÏ‚ 1..24
        hour_cols = []
        for c in df.columns:
            try:
                val = float(c)
                if 1 <= val <= 24:
                    hour_cols.append(c)
            except Exception:
                continue

        if not hour_cols:
            return None

        # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚
        df[date_col] = pd.to_datetime(df[date_col], dayfirst=True, errors="coerce")
        df = df.dropna(subset=[date_col])

        for c in hour_cols:
            df[c] = pd.to_numeric(df[c], errors="coerce")

        # Wide -> Long
        long_df = df.melt(
            id_vars=[date_col],
            value_vars=hour_cols,
            var_name="hour",
            value_name="load",
        )

        long_df = long_df.dropna(subset=["load"])

        # hour: "1" -> 1, "1.0" -> 1
        long_df["hour"] = (
            long_df["hour"].astype(str).str.extract(r"(\d+)").astype(int)
        )

        # timestamp = date + (hour-1) hours
        long_df["timestamp"] = long_df[date_col] + pd.to_timedelta(
            long_df["hour"] - 1, unit="H"
        )

        out = long_df[["timestamp", "load"]].copy()
        out = out.dropna(subset=["timestamp", "load"])

        if out.empty:
            return None

        # merge Ï€Î¹Î¸Î±Î½ÏÎ½ Î´Î¹Ï€Î»Î¿ÎµÎ³Î³ÏÎ±Ï†ÏÎ½
        out = (
            out.groupby("timestamp")["load"]
            .mean()
            .reset_index()
            .sort_values("timestamp")
        )

        return out

    except Exception:
        return None


# ----------------- main ----------------- #
def main():
    print("âš™ï¸ Building HOURLY dataset from HenEx + ADMIE...")

    # --- HenEx prices (hourly) --- #
    henex_files = []
    for d in HENEX_DIRS:
        henex_files.extend(sorted(d.glob("*.xls*")))

    print(f"   HenEx dirs: {[d.name for d in HENEX_DIRS]}")
    print(f"   Found {len(henex_files)} HenEx Excel files.")

    henex_parts = []
    for i, f in enumerate(henex_files):
        part = parse_henex_file(f)
        if part is not None:
            henex_parts.append(part)
        if (i + 1) % 200 == 0:
            print(f"      ...parsed {i+1} HenEx files (ok: {len(henex_parts)})")

    if not henex_parts:
        print("âŒ No HenEx hourly data parsed. Check file pattern/structure.")
        return

    henex_all = pd.concat(henex_parts, ignore_index=True)
    henex_all = (
        henex_all.groupby("timestamp")["price"]
        .mean()
        .reset_index()
        .sort_values("timestamp")
    )

    print(
        f"   âœ… HenEx hourly prices: {len(henex_all)} rows "
        f"({henex_all['timestamp'].min()} â†’ {henex_all['timestamp'].max()})"
    )

    # --- ADMIE load (hourly) --- #
    load_files = sorted(LOAD_DIR.glob("*.xls*"))
    print(f"   ADMIE load dir: {LOAD_DIR.name} | files: {len(load_files)}")

    load_parts = []
    for i, f in enumerate(load_files):
        part = parse_admie_load_hourly(f)
        if part is not None:
            load_parts.append(part)
        if (i + 1) % 200 == 0:
            print(f"      ...parsed {i+1} load files (ok: {len(load_parts)})")

    if not load_parts:
        print("âŒ No ADMIE hourly load parsed. Check load files.")
        return

    load_all = pd.concat(load_parts, ignore_index=True)
    load_all = (
        load_all.groupby("timestamp")["load"]
        .mean()
        .reset_index()
        .sort_values("timestamp")
    )

    print(
        f"   âœ… ADMIE hourly load: {len(load_all)} rows "
        f"({load_all['timestamp'].min()} â†’ {load_all['timestamp'].max()})"
    )

    # --- Merge price + load --- #
    merged = pd.merge(
        henex_all, load_all, on="timestamp", how="inner"
    ).sort_values("timestamp")

    print(f"   ğŸ”— After INNER JOIN: {len(merged)} hourly rows.")

    # keep Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î¸Î­Î»Î¿Ï…Î¼Îµ Ï€ÏÎ¿Ï‚ Ï„Î¿ Ï€Î±ÏÏŒÎ½
    merged = merged.set_index("timestamp")
    merged.index.name = "timestamp"

    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    merged.to_parquet(OUT_PATH)

    print("âœ… Saved hourly dataset:")
    print(f"   {OUT_PATH}")
    print(merged.head(10))
    print(merged.tail(10))


if __name__ == "__main__":
    main()
