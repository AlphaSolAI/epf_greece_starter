import pandas as pd
import numpy as np
from pathlib import Path
import sys
import io
import warnings

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
warnings.filterwarnings('ignore')

LOAD_DIR = Path(__file__).resolve().parents[1] / "data" / "raw" / "load"
DAILY_PARQUET = Path(__file__).resolve().parents[1] / "data" / "processed" / "daily.parquet"

def parse_binary_xls(filepath):
    """
    Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ Binary .xls (OLE2) Î±ÏÏ‡ÎµÎ¯Î± Ï„Î¿Ï… Î‘Î”ÎœÎ—Î•.
    Î¨Î¬Ï‡Î½ÎµÎ¹ Ï„Î· Î³ÏÎ±Î¼Î¼Î® Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï„Î± headers 'Date' ÎºÎ±Î¹ Ï„Î¹Ï‚ ÏÏÎµÏ‚ '1', '2'...
    """
    try:
        # 1. Î”Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Ï€ÏÏÏ„ÎµÏ‚ 20 Î³ÏÎ±Î¼Î¼Î­Ï‚ Ï‡Ï‰ÏÎ¯Ï‚ header Î³Î¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï€Î¿Ï ÎµÎ¯Î½Î±Î¹ Ï„Î± data
        # engine='xlrd' ÎµÎ¯Î½Î±Î¹ Î¥Î ÎŸÎ§Î¡Î•Î©Î¤Î™ÎšÎŸ Î³Î¹Î± Î±Ï…Ï„Î¬ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î±
        df_scan = pd.read_excel(filepath, header=None, nrows=20, engine='xlrd')
        
        header_idx = -1
        for i, row in df_scan.iterrows():
            # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ string Î³Î¹Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·
            row_vals = [str(v).strip().lower() for v in row.values]
            
            # Î¤Î¿ ÎºÎ»ÎµÎ¹Î´Î¯: Î— Î³ÏÎ±Î¼Î¼Î® header Î­Ï‡ÎµÎ¹ "date" ÎºÎ±Î¹ Ï„Î¿Î½ Î±ÏÎ¹Î¸Î¼ÏŒ "1" Î® "1.0"
            if any('date' in x or 'Î·Î¼ÎµÏ' in x for x in row_vals) and \
               any(x == '1' or x == '1.0' for x in row_vals):
                header_idx = i
                break
        
        if header_idx == -1:
            return None

        # 2. ÎÎ±Î½Î±Î´Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ Î¼Îµ Ï„Î¿ ÏƒÏ‰ÏƒÏ„ÏŒ header
        df = pd.read_excel(filepath, header=header_idx, engine='xlrd')
        
        # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½
        df.columns = [str(c).strip() for c in df.columns]
        
        # 3. Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ„Î®Î»Î·Ï‚ Date
        date_col = next((c for c in df.columns if 'Date' in c or 'Î—Î¼ÎµÏ' in c), None)
        if not date_col: return None
        
        # 4. Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ„Î·Î»ÏÎ½ ÎÏÎ±Ï‚ (1 Î­Ï‰Ï‚ 24)
        # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î±ÏÎ¹Î¸Î¼Î¿Î¯ 1..24
        hour_cols = []
        for c in df.columns:
            try:
                # ÎœÎµÏÎ¹ÎºÎ­Ï‚ Ï†Î¿ÏÎ­Ï‚ ÎµÎ¯Î½Î±Î¹ float 1.0, Î¼ÎµÏÎ¹ÎºÎ­Ï‚ int 1
                val = float(c)
                if 1 <= val <= 24:
                    hour_cols.append(c)
            except: continue
            
        if not hour_cols: return None

        # 5. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚
        # ÎšÏÎ±Ï„Î¬Î¼Îµ Î¼ÏŒÎ½Î¿ Î³ÏÎ±Î¼Î¼Î­Ï‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ valid date
        df[date_col] = pd.to_datetime(df[date_col], dayfirst=True, errors='coerce')
        df = df.dropna(subset=[date_col])
        
        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï†Î¿ÏÏ„Î¯Ï‰Î½ ÏƒÎµ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚
        for c in hour_cols:
            df[c] = pd.to_numeric(df[c], errors='coerce')
            
        # ÎœÎ­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚ Î³ÏÎ±Î¼Î¼Î®Ï‚ (axis=1) Î³Î¹Î± Ï„Î¹Ï‚ 24 ÏÏÎµÏ‚
        df['daily_load'] = df[hour_cols].mean(axis=1)
        
        return df.set_index(date_col)['daily_load']

    except Exception as e:
        # print(f"Error in {filepath.name}: {e}")
        return None

def main():
    print("ğŸ”Œ Processing Binary XLS Files (xlrd mode)...")
    
    if not DAILY_PARQUET.exists():
        print("âŒ Missing daily.parquet")
        return

    files = list(LOAD_DIR.glob("*"))
    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î± .xls
    files = [f for f in files if f.name.endswith('xls') or f.name.endswith('xlsx')]
    
    print(f"   Found {len(files)} excel files. Scanning...")
    
    all_daily_loads = []
    
    for i, f in enumerate(files):
        daily = parse_binary_xls(f)
        if daily is not None:
            all_daily_loads.append(daily)
            
        if (i+1) % 200 == 0:
            print(f"   ... processed {i+1} files ...")

    if not all_daily_loads:
        print("âŒ FAILED. Î”ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎ± Î½Î± Î²ÏÏ‰ Ï„Î· Î´Î¿Î¼Î® (Date ... 1 ... 24).")
        return

    # Merge
    full_load = pd.concat(all_daily_loads)
    full_load = full_load.groupby(level=0).mean() # Handle duplicates
    
    print(f"   âœ… Success! Extracted load for {len(full_load)} days.")

    # Save
    df_prices = pd.read_parquet(DAILY_PARQUET)
    df_prices.index = pd.to_datetime(df_prices.index)
    
    load_df = full_load.to_frame(name='load')
    load_df.index = pd.to_datetime(load_df.index)
    
    if 'load' in df_prices.columns:
        df_prices = df_prices.drop(columns=['load'])
        
    merged = df_prices.join(load_df, how='left')
    
    # Fill gaps
    before = merged['load'].isna().sum()
    merged['load'] = merged['load'].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')
    
    merged.to_parquet(DAILY_PARQUET)
    print(f"âœ… SAVED daily.parquet WITH LOAD. (Filled {before} gaps)")
    print(merged[['y', 'load']].tail())

if __name__ == "__main__":
    main()