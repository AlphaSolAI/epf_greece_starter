import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import joblib
import sys
import io
import warnings

# Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
warnings.filterwarnings('ignore')

DATA_PATH = Path(__file__).resolve().parents[1] / "data" / "processed" / "daily.parquet"
MODEL_PATH = Path(__file__).resolve().parents[1] / "models" / "mlp_day.pkl"

def main():
    if not DATA_PATH.exists():
        print("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ daily.parquet")
        return

    # 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ·
    df = pd.read_parquet(DATA_PATH)
    X = df.drop(columns=["y"])
    y = df["y"]
    
    print(f"ğŸ§  Dataset MLP (Neural Net): {len(df)} Î·Î¼Î­ÏÎµÏ‚.")

    # 2. Pipeline (Scaling + Neural Network)
    # Î¤Î± Î½ÎµÏ…ÏÏ‰Î½Î¹ÎºÎ¬ "ÏƒÏ€Î¬Î½Îµ" Î±Î½ Î´ÎµÎ½ ÎºÎ¬Î½ÎµÎ¹Ï‚ scaling (StandardScaler)
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('mlp', MLPRegressor(max_iter=1000, early_stopping=True, random_state=42))
    ])

    # 3. Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î³Î¹Î± Optimization
    param_dist = {
        # (50,) = 1 ÎºÏÏ…Ï†ÏŒ ÎµÏ€Î¯Ï€ÎµÎ´Î¿
        # (100, 50) = 2 ÎºÏÏ…Ï†Î¬ ÎµÏ€Î¯Ï€ÎµÎ´Î± (Deep Learning)
        'mlp__hidden_layer_sizes': [(50,), (100,), (100, 50), (50, 50)], 
        'mlp__activation': ['relu', 'tanh'],
        'mlp__alpha': [0.0001, 0.001, 0.01],        # Regularization
        'mlp__learning_rate_init': [0.001, 0.01]    # Î ÏŒÏƒÎ¿ Î³ÏÎ®Î³Î¿ÏÎ± Î¼Î±Î¸Î±Î¯Î½ÎµÎ¹
    }

    tscv = TimeSeriesSplit(n_splits=3)

    print(f"ğŸ” ÎÎµÎºÎ¹Î½Î¬ÎµÎ¹ Ï„Î¿ Optimization Ï„Î¿Ï… MLP Neural Network...")
    print("   (Î”Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚... Ï…Ï€Î¿Î¼Î¿Î½Î®)")
    
    search = RandomizedSearchCV(
        estimator=pipeline,
        param_distributions=param_dist,
        n_iter=10,
        scoring='neg_mean_absolute_error',
        cv=tscv,
        verbose=1,
        n_jobs=-1,
        random_state=42
    )

    # Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
    search.fit(X, y)

    print("\nâœ… Î’Î­Î»Ï„Î¹ÏƒÏ„ÎµÏ‚ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ MLP:")
    print(search.best_params_)
    print(f"   Best CV Score (MAE): {-search.best_score_:.3f}")
    
    # 4. Î¤ÎµÎ»Î¹ÎºÎ® Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· (ÏƒÏ„Î¿ Train set)
    best_model = search.best_estimator_
    test_size = 60
    best_model.fit(X.iloc[:-test_size], y.iloc[:-test_size])
    
    MODEL_PATH.parent.mkdir(exist_ok=True)
    joblib.dump(best_model, MODEL_PATH)
    print(f"ğŸ’¾ Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ MLP Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÏƒÏ„Î¿ {MODEL_PATH}")

if __name__ == "__main__":
    main()