import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import joblib
import sys
import io
import warnings

# Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
warnings.filterwarnings('ignore')

DATA_PATH = Path(__file__).resolve().parents[1] / "data" / "processed" / "daily.parquet"
MODEL_PATH = Path(__file__).resolve().parents[1] / "models" / "svr_day.pkl"

def main():
    if not DATA_PATH.exists():
        print("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ daily.parquet")
        return

    # 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ·
    df = pd.read_parquet(DATA_PATH)
    X = df.drop(columns=["y"])
    y = df["y"]
    
    print(f"Dataset SVR: {len(df)} Î·Î¼Î­ÏÎµÏ‚. Features: {X.shape[1]}")

    # 2. Pipeline (Scaling + Model)
    # Î¤Î¿ SVR ÎµÎ¯Î½Î±Î¹ ÎµÏ…Î±Î¯ÏƒÎ¸Î·Ï„Î¿ ÏƒÏ„Î¹Ï‚ ÎºÎ»Î¯Î¼Î±ÎºÎµÏ‚, Î¸Î­Î»ÎµÎ¹ Î¿Ï€Ï‰ÏƒÎ´Î®Ï€Î¿Ï„Îµ Scaling
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('svr', SVR())
    ])

    # 3. Hyperparameter Grid
    # C: Î ÏŒÏƒÎ¿ Î±Ï…ÏƒÏ„Î·ÏÏŒ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ (ÎœÎµÎ³Î¬Î»Î¿ C = ÎºÎ¯Î½Î´Ï…Î½Î¿Ï‚ overfitting, ÎœÎ¹ÎºÏÏŒ C = underfitting)
    # epsilon: Î¤Î¿ Ï€Î»Î¬Ï„Î¿Ï‚ Ï„Î¿Ï… "ÏƒÏ‰Î»Î®Î½Î±" Î±Î½Î¿Ï‡Î®Ï‚ Î»Î¬Î¸Î¿Ï…Ï‚
    # gamma: Î ÏŒÏƒÎ¿ Î¼Î±ÎºÏÎ¹Î¬ Ï†Ï„Î¬Î½ÎµÎ¹ Î· ÎµÏ€Î¹ÏÏÎ¿Î® ÎºÎ¬Î¸Îµ Î´ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚
    param_dist = {
        'svr__kernel': ['rbf'], # Î¤Î¿ rbf ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÏƒÏ„Î¬Î½Ï„Î±Ï Î³Î¹Î± Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ­Ï‚
        'svr__C': [10, 50, 100, 500, 1000], 
        'svr__epsilon': [0.1, 1, 2, 5],
        'svr__gamma': ['scale', 'auto', 0.01, 0.1]
    }

    tscv = TimeSeriesSplit(n_splits=3)

    print(f"ğŸ” ÎÎµÎºÎ¹Î½Î¬ÎµÎ¹ Ï„Î¿ Optimization Ï„Î¿Ï… SVR...")
    print("   (Î”Î¿ÎºÎ¹Î¼Î¬Î¶Î¿Ï…Î¼Îµ 15 ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼Î¿ÏÏ‚ - Î¸Î± Ï€Î¬ÏÎµÎ¹ Î»Î¯Î³Î¿ Ï‡ÏÏŒÎ½Î¿...)")
    
    search = RandomizedSearchCV(
        estimator=pipeline,
        param_distributions=param_dist,
        n_iter=15,
        scoring='neg_mean_absolute_error',
        cv=tscv,
        verbose=1,
        n_jobs=-1,
        random_state=42
    )

    search.fit(X, y)

    print("\nâœ… Î’Î­Î»Ï„Î¹ÏƒÏ„ÎµÏ‚ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ SVR:")
    print(search.best_params_)
    print(f"   Best CV Score (MAE): {-search.best_score_:.3f}")
    
    # 4. Î¤ÎµÎ»Î¹ÎºÎ® Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
    best_model = search.best_estimator_
    test_size = 60
    best_model.fit(X.iloc[:-test_size], y.iloc[:-test_size])
    
    MODEL_PATH.parent.mkdir(exist_ok=True)
    joblib.dump(best_model, MODEL_PATH)
    print(f"ğŸ’¾ Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ SVR Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÏƒÏ„Î¿ {MODEL_PATH}")

if __name__ == "__main__":
    main()